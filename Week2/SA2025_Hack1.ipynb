{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104491,"databundleVersionId":12585144,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:19.536005Z","iopub.execute_input":"2025-06-12T06:27:19.536355Z","iopub.status.idle":"2025-06-12T06:27:19.544414Z","shell.execute_reply.started":"2025-06-12T06:27:19.536332Z","shell.execute_reply":"2025-06-12T06:27:19.543043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:22.612665Z","iopub.execute_input":"2025-06-12T06:27:22.612984Z","iopub.status.idle":"2025-06-12T06:27:22.618266Z","shell.execute_reply.started":"2025-06-12T06:27:22.612962Z","shell.execute_reply":"2025-06-12T06:27:22.617354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load training data\ndf = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\")\nprint(f\"Training data shape: {df.shape}\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:26.142792Z","iopub.execute_input":"2025-06-12T06:27:26.143630Z","iopub.status.idle":"2025-06-12T06:27:26.208315Z","shell.execute_reply.started":"2025-06-12T06:27:26.143606Z","shell.execute_reply":"2025-06-12T06:27:26.207118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Missing values before cleaning:\\n{df.isnull().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:30.646004Z","iopub.execute_input":"2025-06-12T06:27:30.646362Z","iopub.status.idle":"2025-06-12T06:27:30.656248Z","shell.execute_reply.started":"2025-06-12T06:27:30.646341Z","shell.execute_reply":"2025-06-12T06:27:30.655257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Improved missing value handling by using median instead of mean\nnumeric_columns = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_columns:\n    if col != 'ID':  # Don't fill ID column\n        df[col].fillna(df[col].median(), inplace=True)\n\nprint(f\"Missing values after cleaning:\\n{df.isnull().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:34.544036Z","iopub.execute_input":"2025-06-12T06:27:34.544404Z","iopub.status.idle":"2025-06-12T06:27:34.569895Z","shell.execute_reply.started":"2025-06-12T06:27:34.544381Z","shell.execute_reply":"2025-06-12T06:27:34.568955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic feature engineering \nndvi_columns = [col for col in df.columns if col not in ['ID', 'class']]\n\n# Add some simple time series features\ndf['ndvi_mean'] = df[ndvi_columns].mean(axis=1)\ndf['ndvi_std'] = df[ndvi_columns].std(axis=1)\ndf['ndvi_max'] = df[ndvi_columns].max(axis=1)\ndf['ndvi_min'] = df[ndvi_columns].min(axis=1)\ndf['ndvi_range'] = df['ndvi_max'] - df['ndvi_min']\n\n# Seasonal features (assuming columns are chronologically ordered)\nif len(ndvi_columns) >= 4:\n    quarter_size = len(ndvi_columns) // 4\n    df['ndvi_q1'] = df[ndvi_columns[:quarter_size]].mean(axis=1)\n    df['ndvi_q2'] = df[ndvi_columns[quarter_size:2*quarter_size]].mean(axis=1)\n    df['ndvi_q3'] = df[ndvi_columns[2*quarter_size:3*quarter_size]].mean(axis=1)\n    df['ndvi_q4'] = df[ndvi_columns[3*quarter_size:]].mean(axis=1)\n\nprint(f\"Data shape after feature engineering: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:38.292973Z","iopub.execute_input":"2025-06-12T06:27:38.293825Z","iopub.status.idle":"2025-06-12T06:27:38.335449Z","shell.execute_reply.started":"2025-06-12T06:27:38.293789Z","shell.execute_reply":"2025-06-12T06:27:38.334339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop ID column\ndf.drop(columns=['ID'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:27:43.935902Z","iopub.execute_input":"2025-06-12T06:27:43.936226Z","iopub.status.idle":"2025-06-12T06:27:43.943619Z","shell.execute_reply.started":"2025-06-12T06:27:43.936206Z","shell.execute_reply":"2025-06-12T06:27:43.942669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode target variable\nlabel_encoder = LabelEncoder()\ndf['class'] = label_encoder.fit_transform(df['class'])\n\nprint(f\"Classes: {label_encoder.classes_}\")\nprint(f\"Class distribution:\\n{pd.Series(df['class']).value_counts().sort_index()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:28:25.837155Z","iopub.execute_input":"2025-06-12T06:28:25.837931Z","iopub.status.idle":"2025-06-12T06:28:25.854901Z","shell.execute_reply.started":"2025-06-12T06:28:25.837896Z","shell.execute_reply":"2025-06-12T06:28:25.853969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split features and target\nX = df.drop(columns=['class'])\ny = df['class']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:29:28.060894Z","iopub.execute_input":"2025-06-12T06:29:28.061224Z","iopub.status.idle":"2025-06-12T06:29:28.068069Z","shell.execute_reply.started":"2025-06-12T06:29:28.061203Z","shell.execute_reply":"2025-06-12T06:29:28.067205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:29:50.531896Z","iopub.execute_input":"2025-06-12T06:29:50.532271Z","iopub.status.idle":"2025-06-12T06:29:50.555264Z","shell.execute_reply.started":"2025-06-12T06:29:50.532246Z","shell.execute_reply":"2025-06-12T06:29:50.554462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:32:43.345340Z","iopub.execute_input":"2025-06-12T06:32:43.346276Z","iopub.status.idle":"2025-06-12T06:32:43.359815Z","shell.execute_reply.started":"2025-06-12T06:32:43.346246Z","shell.execute_reply":"2025-06-12T06:32:43.358883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try multiple simple models and pick the best one\nmodels = {\n    'Logistic Regression': LogisticRegression(\n        multi_class='multinomial',\n        solver='lbfgs',\n        max_iter=1000,  # Increased iterations\n        random_state=42,\n        C=1.0  # Regularization parameter\n    ),\n    'Random Forest': RandomForestClassifier(\n        n_estimators=100,\n        random_state=42,\n        max_depth=10,  # Prevent overfitting\n        min_samples_split=5,\n        min_samples_leaf=2\n    )\n}\n\nbest_model = None\nbest_score = 0\nbest_name = \"\"\n\nprint(\"\\nModel Comparison (5-fold CV):\")\nfor name, model in models.items():\n    # Cross-validation\n    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n    mean_score = cv_scores.mean()\n    std_score = cv_scores.std()\n    \n    print(f\"{name}: {mean_score:.4f} (+/- {std_score*2:.4f})\")\n    \n    if mean_score > best_score:\n        best_score = mean_score\n        best_model = model\n        best_name = name\n\nprint(f\"\\nBest model: {best_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:32:46.653207Z","iopub.execute_input":"2025-06-12T06:32:46.653588Z","iopub.status.idle":"2025-06-12T06:33:01.777212Z","shell.execute_reply.started":"2025-06-12T06:32:46.653562Z","shell.execute_reply":"2025-06-12T06:33:01.776046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the best model\nbest_model.fit(X_train, y_train)\n\n# Evaluate on validation set\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n\n# Detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    y_test,\n    y_pred,\n    labels=list(range(len(label_encoder.classes_))),\n    target_names=label_encoder.classes_\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:34:34.790150Z","iopub.execute_input":"2025-06-12T06:34:34.790927Z","iopub.status.idle":"2025-06-12T06:34:37.564527Z","shell.execute_reply.started":"2025-06-12T06:34:34.790901Z","shell.execute_reply":"2025-06-12T06:34:37.563503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test data\ntest_data = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\")\nprint(f\"\\nTest data shape: {test_data.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:35:36.009403Z","iopub.execute_input":"2025-06-12T06:35:36.010514Z","iopub.status.idle":"2025-06-12T06:35:36.034638Z","shell.execute_reply.started":"2025-06-12T06:35:36.010479Z","shell.execute_reply":"2025-06-12T06:35:36.033446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Store IDs\ntest_ids = test_data['ID'].copy()\n\n# Drop ID column\ntest_data.drop(['ID'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:35:40.118088Z","iopub.execute_input":"2025-06-12T06:35:40.118466Z","iopub.status.idle":"2025-06-12T06:35:40.124739Z","shell.execute_reply.started":"2025-06-12T06:35:40.118441Z","shell.execute_reply":"2025-06-12T06:35:40.123747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handle missing values in test data (same way as training data)\nfor col in test_data.columns:\n    if test_data[col].isnull().any():\n        # Use training data statistics for imputation\n        train_median = df[col].median() if col in df.columns else test_data[col].median()\n        test_data[col].fillna(train_median, inplace=True)\n\n# Apply same feature engineering to test data\ntest_ndvi_columns = [col for col in test_data.columns]\n\ntest_data['ndvi_mean'] = test_data[test_ndvi_columns].mean(axis=1)\ntest_data['ndvi_std'] = test_data[test_ndvi_columns].std(axis=1)\ntest_data['ndvi_max'] = test_data[test_ndvi_columns].max(axis=1)\ntest_data['ndvi_min'] = test_data[test_ndvi_columns].min(axis=1)\ntest_data['ndvi_range'] = test_data['ndvi_max'] - test_data['ndvi_min']\n\n# Seasonal features for test data\nif len(test_ndvi_columns) >= 4:\n    quarter_size = len(test_ndvi_columns) // 4\n    test_data['ndvi_q1'] = test_data[test_ndvi_columns[:quarter_size]].mean(axis=1)\n    test_data['ndvi_q2'] = test_data[test_ndvi_columns[quarter_size:2*quarter_size]].mean(axis=1)\n    test_data['ndvi_q3'] = test_data[test_ndvi_columns[2*quarter_size:3*quarter_size]].mean(axis=1)\n    test_data['ndvi_q4'] = test_data[test_ndvi_columns[3*quarter_size:]].mean(axis=1)\n\n# Scale test data using the same scaler\ntest_data_scaled = scaler.transform(test_data)\n\n# Make predictions\ny_test_pred = best_model.predict(test_data_scaled)\n\n# Convert predictions back to original class labels\ny_decoded = label_encoder.inverse_transform(y_test_pred)\n\nprint(f\"\\nPrediction distribution:\")\nunique, counts = np.unique(y_decoded, return_counts=True)\nfor class_name, count in zip(unique, counts):\n    print(f\"{class_name}: {count}\")\n\n# Create submission file\nresult = pd.DataFrame({\n    'ID': test_ids,\n    'class': y_decoded\n})\n\nprint(f\"\\nSubmission shape: {result.shape}\")\nprint(result)\n\n# Save submission\nresult.to_csv(\"submission.csv\", index=False)\nprint(\"\\nSubmission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:38:59.313574Z","iopub.execute_input":"2025-06-12T06:38:59.314629Z","iopub.status.idle":"2025-06-12T06:38:59.398361Z","shell.execute_reply.started":"2025-06-12T06:38:59.314588Z","shell.execute_reply":"2025-06-12T06:38:59.397481Z"}},"outputs":[],"execution_count":null}]}